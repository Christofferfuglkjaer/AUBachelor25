{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[neptune] [warning] NeptuneWarning: By default, these monitoring options are disabled in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', 'capture_hardware_metrics'. You can set them to 'True' when initializing the run and the monitoring will continue until you call run.stop() or the kernel stops. NOTE: To track the source files, pass their paths to the 'source_code' argument. For help, see: https://docs.neptune.ai/logging/source_code/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/momkeybomkey/Federated/e/FED-20\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from medmnist import PneumoniaMNIST\n",
    "import torch\n",
    "import random\n",
    "import copy\n",
    "\n",
    "from skimage.io import imshow\n",
    "import neptune\n",
    "run = neptune.init_run(project='momkeybomkey/Federated',\n",
    "                       api_token='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJjNDdlN2ZhNy00ZmJmLTQ4YjMtYTk0YS1lNmViZmZjZWRhNzUifQ=='\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _collate_fn(data):\n",
    "        xs = []\n",
    "\n",
    "        for x, _ in data:\n",
    "            x = np.array(x).astype(np.float32) / 255.\n",
    "            xs.append([x])\n",
    "\n",
    "        return np.array(xs)\n",
    "\n",
    "def shuffle_iterator(iterator):\n",
    "    # iterator should have limited size\n",
    "    index = list(iterator)\n",
    "    total_size = len(index)\n",
    "    i = 0\n",
    "    random.shuffle(index)\n",
    "    result = []\n",
    "\n",
    "    while len(result) < total_size:\n",
    "        result.append(index[i])\n",
    "        i += 1\n",
    "        \n",
    "        if i >= total_size:\n",
    "            i = 0\n",
    "            random.shuffle(index)\n",
    "\n",
    "    return result\n",
    "\n",
    "def get_loader(dataset, random):\n",
    "    total_size = len(dataset)\n",
    "    print('Size', total_size)\n",
    "    if random:\n",
    "        index_generator = shuffle_iterator(range(total_size))\n",
    "    else:\n",
    "        index_generator = list(range(total_size))\n",
    "\n",
    "    while True:\n",
    "        data = []\n",
    "\n",
    "        for _ in range(len(index_generator)):\n",
    "            idx = index_generator.pop()\n",
    "            data.append(dataset[idx])\n",
    "\n",
    "        return _collate_fn(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise(data, noise_factor = 0.2):\n",
    "    data += noise_factor * np.random.normal(size=data.shape)\n",
    "    data = np.clip(data, 0., 1.)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def even_data(split):\n",
    "    min_size = min([len(data) for data in split])\n",
    "    return [data[:min_size] for data in split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, n, noise_factor = 0.1):\n",
    "    m = len(data)\n",
    "    data_copy = copy.deepcopy(data)\n",
    "    clean_split = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        clean_split.append(data_copy[m * i // n: m * (i + 1) // n])\n",
    "\n",
    "    clean_split = even_data(clean_split)\n",
    "    noisy_split = copy.deepcopy(clean_split)\n",
    "    noisy_split = [generate_noise(x, noise_factor) for x in noisy_split]\n",
    "\n",
    "    clean_split = np.clip(np.array(clean_split), 0., 1.)\n",
    "    noisy_split = np.clip(np.array(noisy_split), 0., 1.)\n",
    "    \n",
    "    clean_split = torch.tensor(clean_split).float()\n",
    "    noisy_split = torch.tensor(noisy_split).float()\n",
    "\n",
    "    clean_split = clean_split.to(device)\n",
    "    noisy_split = noisy_split.to(device)\n",
    "\n",
    "    return clean_split, noisy_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: C:\\Users\\malth\\.medmnist\\pneumoniamnist_128.npz\n",
      "Using downloaded and verified file: C:\\Users\\malth\\.medmnist\\pneumoniamnist_128.npz\n",
      "Using downloaded and verified file: C:\\Users\\malth\\.medmnist\\pneumoniamnist_128.npz\n",
      "Size 4708\n",
      "Size 624\n",
      "Size 524\n"
     ]
    }
   ],
   "source": [
    "train = PneumoniaMNIST(split=\"train\", download=True, size=128)\n",
    "test = PneumoniaMNIST(split=\"test\", download=True, size=128)\n",
    "val = PneumoniaMNIST(split=\"val\", download=True, size=128)\n",
    "\n",
    "train_loader = get_loader(train, random=True)\n",
    "test_loader = get_loader(test, random=True)\n",
    "\n",
    "val_loader = get_loader(val, random=False)\n",
    "\n",
    "val_clean, val_noisy = split_data(val_loader, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 524, 1, 128, 128])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_clean.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(y_true, y_pred):\n",
    "    return 20 * torch.log10(torch.max(y_true) / loss_fn(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neptune_log(epoch, model, loss, psnr):\n",
    "    print(\"Evaluation\")\n",
    "    run[\"evaluation/mse\"].append(loss)\n",
    "    run[\"evaluation/psnr\"].append(psnr) \n",
    "    run[f\"images/reconstructed_{epoch + 1}\"].upload(neptune.types.File.as_image(model(val_noisy[0][0])[0].cpu().detach().numpy()))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neptune_val_images(model):\n",
    "    print(\"Final evaluation\")\n",
    "    \n",
    "    for i in range(1, 6):\n",
    "        run[f\"validation/original_{i}\"].upload(neptune.types.File.as_image(val_clean[0][i][0].cpu().detach().numpy()))\n",
    "        run[f\"validation/noisy_{i}\"].upload(neptune.types.File.as_image(val_noisy[0][i][0].cpu().detach().numpy()))\n",
    "        run[f\"validation/reconstructed_{i}\"].upload(neptune.types.File.as_image(model(val_noisy[0][i])[0].cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limited data\n",
    "# train_load = split_data(train_load, 5)\n",
    "# test_load = split_data(test_load, 5)\n",
    "\n",
    "# train_load = train_load[0][0]\n",
    "# test_load = test_load[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 16, 3, stride=2, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(64, 64, 3, stride=2, padding=1),\n",
    "            torch.nn.Flatten(0, -1),\n",
    "            torch.nn.Linear(64 * 8 * 8, 128)\n",
    "        )\n",
    "\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(128, 64 * 8 * 8),\n",
    "            torch.nn.Unflatten(0, (64, 8, 8)),\n",
    "            torch.nn.ConvTranspose2d(64, 64, 3, stride=2, padding=1, output_padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(n, epochs):\n",
    "    # Make overall model\n",
    "    autoencoder = AE()\n",
    "    autoencoder.to(device)\n",
    "\n",
    "    try:\n",
    "        autoencoder.load_state_dict(torch.load(\"./Models/model_test.pth\"))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # neptune_log(-1, autoencoder)\n",
    "    run[\"images/original\"].upload(neptune.types.File.as_image(val_clean[0][0][0].cpu().numpy()))\n",
    "    run[\"images/noisy\"].upload(neptune.types.File.as_image(val_noisy[0][0][0].cpu().numpy()))\n",
    "\n",
    "    # Make n models\n",
    "    models = [AE() for _ in range(n)]\n",
    "    \n",
    "\n",
    "    # Split data\n",
    "    train, train_noisy = split_data(train_loader, n)\n",
    "    test, test_noisy = split_data(test_loader, n)\n",
    "\n",
    "    # Get central weights\n",
    "    primary_weights = autoencoder.state_dict()\n",
    "    for model in models:\n",
    "        model.to(device)\n",
    "        model.load_state_dict(primary_weights)\n",
    "    \n",
    "    # Train the networks\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}\")\n",
    "\n",
    "        for i, model in enumerate(models):\n",
    "            print(f\"Autoencoder {i + 1}\")\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "            total_loss = 0\n",
    "            total_psnr = 0\n",
    "\n",
    "            for j in range(len(train[i])):\n",
    "                optimizer.zero_grad()\n",
    "                loss = loss_fn(model(train_noisy[i][j]), train[i][j])\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            for noisy, clean in zip(test_noisy[i], test[i]):\n",
    "                loss = loss_fn(model(noisy), clean)\n",
    "                total_loss += loss.item()\n",
    "                total_psnr += PSNR(model(noisy), clean).item()\n",
    "\n",
    "            total_loss /= len(test[i])\n",
    "            total_psnr /= len(test[i])\n",
    "            run[f\"evaluation/autoencoder_{i + 1}/mse\"].append(total_loss)\n",
    "            run[f\"evaluation/autoencoder_{i + 1}/psnr\"].append(total_psnr)\n",
    "            print(f\"Loss {total_loss}\")\n",
    "            print(f\"PSNR {total_psnr}\")\n",
    "\n",
    "        # Aggregate the models\n",
    "        for key in primary_weights.keys():\n",
    "            primary_weights[key] = sum([model.state_dict()[key] for model in models]) / n\n",
    "\n",
    "        for model in models:\n",
    "            model.load_state_dict(primary_weights)\n",
    "\n",
    "        autoencoder.load_state_dict(primary_weights)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1} completed\")\n",
    "        \n",
    "        total_loss = 0\n",
    "        total_psnr = 0\n",
    "\n",
    "        for noisy, clean in zip(val_noisy[0], val_clean[0]):\n",
    "            loss = loss_fn(autoencoder(noisy), clean)\n",
    "            total_loss += loss.item()\n",
    "            total_psnr += PSNR(autoencoder(noisy), clean).item()\n",
    "        \n",
    "        total_loss /= len(val_noisy[0])\n",
    "        total_psnr /= len(val_noisy[0])\n",
    "\n",
    "        print(f\"Validation Loss {total_loss}\")\n",
    "        print(f\"Validation PSNR {total_psnr}\")\n",
    "        print(\"\")\n",
    "\n",
    "        neptune_log(epoch, autoencoder, total_loss, total_psnr)\n",
    "\n",
    "        torch.save(autoencoder.state_dict(), \"./Models/model_test.pth\")\n",
    "    \n",
    "    neptune_val_images(autoencoder)\n",
    "\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malth\\AppData\\Local\\Temp\\ipykernel_3580\\2248712902.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  autoencoder.load_state_dict(torch.load(\"./Models/model_test.pth\"))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m autoencoder \u001b[38;5;241m=\u001b[39m \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[30], line 20\u001b[0m, in \u001b[0;36mrun_model\u001b[1;34m(n, epochs)\u001b[0m\n\u001b[0;32m     16\u001b[0m models \u001b[38;5;241m=\u001b[39m [AE() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n)]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Split data\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m train, train_noisy \u001b[38;5;241m=\u001b[39m \u001b[43msplit_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m test, test_noisy \u001b[38;5;241m=\u001b[39m split_data(test_loader, n)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Get central weights\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m, in \u001b[0;36msplit_data\u001b[1;34m(data, n, noise_factor)\u001b[0m\n\u001b[0;32m      9\u001b[0m clean_split \u001b[38;5;241m=\u001b[39m even_data(clean_split)\n\u001b[0;32m     10\u001b[0m noisy_split \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(clean_split)\n\u001b[1;32m---> 11\u001b[0m noisy_split \u001b[38;5;241m=\u001b[39m [\u001b[43mgenerate_noise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_factor\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m noisy_split]\n\u001b[0;32m     13\u001b[0m clean_split \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(np\u001b[38;5;241m.\u001b[39marray(clean_split), \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m1.\u001b[39m)\n\u001b[0;32m     14\u001b[0m noisy_split \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(np\u001b[38;5;241m.\u001b[39marray(noisy_split), \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m1.\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m, in \u001b[0;36mgenerate_noise\u001b[1;34m(data, noise_factor)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_noise\u001b[39m(data, noise_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m noise_factor \u001b[38;5;241m*\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(data, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m1.\u001b[39m)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "autoencoder = run_model(5, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
