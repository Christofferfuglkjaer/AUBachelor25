{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers, losses\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfds\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Mode\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input, Dense, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, UpSampling2D, add\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_datasets'"
     ]
    }
   ],
   "source": [
    "from medmnist import PneumoniaMNIST\n",
    "import numpy as np\n",
    "from medmnist import INFO, Evaluator\n",
    "import matplotlib.image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from skimage.io import imshow, imread,imsave\n",
    "from skimage.util import random_noise\n",
    "import skimage.io\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import dataset_without_pytorch\n",
    "\n",
    "from dataset_without_pytorch import get_loader\n",
    "import keras_tuner\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.models import Mode\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, UpSampling2D, add\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "PneumoniaMNIST(split='train',download=True, size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flag = 'pneumoniamnist'\n",
    "# data_flag = 'breastmnist'\n",
    "download = True\n",
    "\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 128\n",
    "lr = 0.001\n",
    "\n",
    "info = INFO[data_flag]\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "\n",
    "DataClass = getattr(dataset_without_pytorch, info['python_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/christofferfuglkjaer/.medmnist/pneumoniamnist_128.npz\n",
      "Using downloaded and verified file: /Users/christofferfuglkjaer/.medmnist/pneumoniamnist_128.npz\n",
      "Using downloaded and verified file: /Users/christofferfuglkjaer/.medmnist/pneumoniamnist_128.npz\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "train_dataset = DataClass(split='train', download=download,size = 128)\n",
    "test_dataset = DataClass(split='test', download=download,size = 128)\n",
    "val_dataset= DataClass(split='val', download=download,size = 128)\n",
    "\n",
    "\n",
    "# encapsulate data into dataloader form\n",
    "train_loader = get_loader(dataset=train_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = get_loader(dataset = test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(524, 128, 128)\n",
      "(624, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "train_file = np.load('/Users/christofferfuglkjaer/.medmnist/pneumoniamnist_128.npz')\n",
    "\n",
    "x_train = train_file['train_images']\n",
    "x_test = train_file['test_images']\n",
    "x_val = train_file['val_images']\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_val=x_val.astype('float32') / 255.\n",
    "\n",
    "print (x_val.shape)\n",
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 10:42:41.726951: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2025-02-10 10:42:41.726990: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-02-10 10:42:41.726994: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-02-10 10:42:41.727335: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-02-10 10:42:41.727777: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "noise_factor = 0.2\n",
    "\n",
    "x_train_noisy = x_train + noise_factor * tf.random.normal(shape=x_train.shape)\n",
    "x_test_noisy = x_test + noise_factor * tf.random.normal(shape=x_test.shape)\n",
    "x_val_noisy = x_val + noise_factor * tf.random.normal(shape=x_val.shape)\n",
    "\n",
    "x_train_noisy = tf.clip_by_value(x_train_noisy, clip_value_min=0., clip_value_max=1.)\n",
    "x_test_noisy = tf.clip_by_value(x_test_noisy, clip_value_min=0., clip_value_max=1.)\n",
    "x_val_noisy = tf.clip_by_value(x_val_noisy, clip_value_min=0., clip_value_max=1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i + 1)\n",
    "    plt.title(\"original + noise\")\n",
    "    plt.imshow(tf.squeeze(x_test_noisy[i]))\n",
    "    plt.gray()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, UpSampling2D, add\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "# Encoder\n",
    "\n",
    "n = 128\n",
    "chan = 1\n",
    "input_img = Input(shape=(n, n, chan))\n",
    "\n",
    "l1 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(input_img)\n",
    "l2 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l1)\n",
    "l3 = MaxPooling2D(padding='same')(l2)\n",
    "#l3 = Dropout(0.3)(l3)\n",
    "l4 = Conv2D(64, (3, 3),  padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l3)\n",
    "l5 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l4)\n",
    "l6 = MaxPooling2D(padding='same')(l5)\n",
    "#l3 = Dropout(0.5)(l3)\n",
    "l7 = Conv2D(128, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l6)\n",
    "encoder = Model(input_img, l7)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, UpSampling2D, add\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "# Encoder\n",
    "\n",
    "n = 128\n",
    "chan = 1\n",
    "input_img = Input(shape=(n, n, chan))\n",
    "\n",
    "l1 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(input_img)\n",
    "l2 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l1)\n",
    "l3 = MaxPooling2D(padding='same')(l2)\n",
    "#l3 = Dropout(0.3)(l3)\n",
    "l4 = Conv2D(64, (3, 3),  padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l3)\n",
    "l5 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l4)\n",
    "l6 = MaxPooling2D(padding='same')(l5)\n",
    "#l3 = Dropout(0.5)(l3)\n",
    "l7 = Conv2D(128, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l6)\n",
    "encoder = Model(input_img, l7)\n",
    "encoder.summary()\n",
    "\n",
    "# Decoder\n",
    "\n",
    "l8 = UpSampling2D()(l6)\n",
    "\n",
    "l9 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10),)(l8)\n",
    "l10 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l9)\n",
    "\n",
    "l11 = add([l5, l10])\n",
    "l12 = UpSampling2D()(l11)\n",
    "#l3 = Dropout(0.3)(l3)\n",
    "l13 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l12)\n",
    "l14 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l13)\n",
    "\n",
    "l15 = add([l14, l2])\n",
    "\n",
    "# chan = 3, for RGB\n",
    "decoded = Conv2D(chan, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l15)\n",
    "\n",
    "# Create our network\n",
    "autoencoder = Model(input_img, decoded)\n",
    "# You'll understand later what this is\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tuner.search(x_train, y_train, epochs=5, validation_data=(x_val, y_val))\n",
    "best_model = tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001), loss=losses.MeanSquaredError())\n",
    "autoencoder.fit(x_train_noisy, x_train,epochs=25,batch_size = 16,shuffle=True, validation_data=(x_test_noisy, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_weights = autoencoder.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(x_val[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs=autoencoder.predict(x_val_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(decoded_imgs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_imgs = autoencoder.encoder(x_test_noisy).numpy()\n",
    "# decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(orig, res):\n",
    "    return ((orig - res) ** 2).mean()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "n = 5\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(3, n, i + 1)\n",
    "    plt.imshow(x_test[i])\n",
    "    plt.title(\"original\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # display noisy\n",
    "    ax = plt.subplot(3, n, i + 1 + n)\n",
    "    plt.imshow(x_test_noisy[i])\n",
    "    plt.title(\"noisy\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(3, n, i + 1 + 2 * n)\n",
    "    plt.imshow(decoded_imgs[i])\n",
    "    plt.title(\"reconstructed\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(True)\n",
    "    plt.xlabel(mse(x_test[i], decoded_imgs[i]))\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(decoded_imgs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiple \"networks\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 50/50 netværk \n",
    "2) 4* 25 netværk\n",
    "3) 10 * 10 netværk\n",
    "\n",
    "planen er at træne det her netværk seperat og bruge noget magic til at sætte vægtene sammen til et netværk og så evaluerer dem mod det fulde netværk \n",
    "\n",
    "Vi kører alle netværk ved 25 epoker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_train_noisy_501 = np.split(x_train_noisy,2)\n",
    "x_testnoisy_501 = np.split(x_test_noisy,2)\n",
    "x_train_501 = np.split(x_train,2)\n",
    "x_test_501 = np.split(x_test,2)\n",
    "x_val_noisy501 = np.split(x_val_noisy,2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 50.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 128\n",
    "chan = 1\n",
    "\n",
    "weights = []\n",
    "epochs = 1\n",
    "batchsize = 8\n",
    "\n",
    "for i in range(len(x_train_501)):\n",
    "    print(f\"starter på at træne netværk {i+1}\")\n",
    "\n",
    "    input_img = Input(shape=(n, n, chan))\n",
    "\n",
    "    l1 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(input_img)\n",
    "    l2 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l1)\n",
    "    l3 = MaxPooling2D(padding='same')(l2)\n",
    "    #l3 = Dropout(0.3)(l3)\n",
    "    l4 = Conv2D(64, (3, 3),  padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l3)\n",
    "    l5 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l4)\n",
    "    l6 = MaxPooling2D(padding='same')(l5)\n",
    "    #l3 = Dropout(0.5)(l3)\n",
    "    l7 = Conv2D(128, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l6)\n",
    "    encoder = Model(input_img, l7)\n",
    "\n",
    "\n",
    "    # Decoder\n",
    "\n",
    "    l8 = UpSampling2D()(l6)\n",
    "\n",
    "    l9 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10),)(l8)\n",
    "    l10 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l9)\n",
    "\n",
    "    l11 = add([l5, l10])\n",
    "    l12 = UpSampling2D()(l11)\n",
    "    #l3 = Dropout(0.3)(l3)\n",
    "    l13 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l12)\n",
    "    l14 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l13)\n",
    "\n",
    "    l15 = add([l14, l2])\n",
    "\n",
    "\n",
    "    decoded = Conv2D(chan, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l15)\n",
    "\n",
    "    # Create our network\n",
    "    autoencoder501 = Model(input_img, decoded)\n",
    "\n",
    "    autoencoder501.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001), loss=losses.MeanSquaredError())\n",
    "    autoencoder501.fit(x_train_noisy_501[i], x_train_501[i],epochs=50,batch_size = 8,shuffle=True, validation_data=(x_testnoisy_501[i], x_test_501[i]))\n",
    "    weights.append(autoencoder501.get_weights())\n",
    "    print(f\"netværk {i+1} er færdig med at gøre, går videre til netværk {i+2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs=autoencoder.predict(x_val_noisy501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the arrays have the same shape\n",
    "same_shape = all(w1.shape == w2.shape for w1, w2 in zip(weights_501, weights_502))\n",
    "print(same_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de = autoencoder501.predict(x_val)\n",
    "imshow(de[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.evaluate(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights50501 = [ori - w1 for ori, w1 in zip(ori_weights, weights_501)]\n",
    "weights50502 = [ori - w2 for ori, w2 in zip(ori_weights, weights_502)]\n",
    "weights5050 = [(w1 +w2)/2 + ori for w1, w2,ori in zip(weights50501, weights50502, ori_weights)]\n",
    "autoencoder.set_weights(weights5050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_val)\n",
    "imshow(decoded_imgs[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 25-25\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noisy25 = np.split(x_train_noisy,4)\n",
    "x_train25 = np.split(x_train,4)\n",
    "x_test_noisy25 = np.split(x_test_noisy,4)\n",
    "x_test25 = np.split(x_test , 4)\n",
    "x_val25 = np.split(x_val_noisy,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "epochs = 25\n",
    "batchsize = 8\n",
    "agg = 2\n",
    "n = 128\n",
    "chan = 1\n",
    "\n",
    "for j in agg:\n",
    "    for i in range(len(x_train25)):\n",
    "    print(f\"starter med at træne netværk {i+1}.\")\n",
    "\n",
    "    input_img = Input(shape=(n, n, chan))\n",
    "\n",
    "    l1 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(input_img)\n",
    "    l2 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l1)\n",
    "    l3 = MaxPooling2D(padding='same')(l2)\n",
    "    #l3 = Dropout(0.3)(l3)\n",
    "    l4 = Conv2D(64, (3, 3),  padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l3)\n",
    "    l5 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l4)\n",
    "    l6 = MaxPooling2D(padding='same')(l5)\n",
    "    #l3 = Dropout(0.5)(l3)\n",
    "    l7 = Conv2D(128, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l6)\n",
    "    encoder = Model(input_img, l7)\n",
    "\n",
    "\n",
    "    # Decoder\n",
    "\n",
    "    l8 = UpSampling2D()(l6)\n",
    "\n",
    "    l9 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10),)(l8)\n",
    "    l10 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l9)\n",
    "\n",
    "    l11 = add([l5, l10])\n",
    "    l12 = UpSampling2D()(l11)\n",
    "    #l3 = Dropout(0.3)(l3)\n",
    "    l13 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l12)\n",
    "    l14 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l13)\n",
    "\n",
    "    l15 = add([l14, l2])\n",
    "\n",
    "    # chan = 3,$ for RGB\n",
    "    decoded = Conv2D(chan, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l15)\n",
    "\n",
    "    # Create our network\n",
    "    autoencoder25 = Model(input_img, decoded)\n",
    "    # You'll understand later what this is\n",
    "\n",
    "    autoencoder25.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001), loss=losses.MeanSquaredError())\n",
    "    autoencoder25.fit(x_train_noisy25[i], x_train25[i],epochs=epochs,batch_size = batchsize,shuffle=True, validation_data=(x_test_noisy25[i], x_test25[i]),verbose=0,)\n",
    "    y = autoencoder25.get_weights()\n",
    "    weights.append(y)\n",
    "    print(f\"netværk {i+1} er færdig med at gøre, går videre til netværk {i+2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
