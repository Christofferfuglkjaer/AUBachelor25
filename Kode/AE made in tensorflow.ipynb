{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/christofferfuglkjaer/.medmnist/pneumoniamnist_128.npz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset PneumoniaMNIST of size 128 (pneumoniamnist_128)\n",
       "    Number of datapoints: 4708\n",
       "    Root location: /Users/christofferfuglkjaer/.medmnist\n",
       "    Split: train\n",
       "    Task: binary-class\n",
       "    Number of channels: 1\n",
       "    Meaning of labels: {'0': 'normal', '1': 'pneumonia'}\n",
       "    Number of samples: {'train': 4708, 'val': 524, 'test': 624}\n",
       "    Description: The PneumoniaMNIST is based on a prior dataset of 5,856 pediatric chest X-Ray images. The task is binary-class classification of pneumonia against normal. We split the source training set with a ratio of 9:1 into training and validation set and use its source validation set as the test set. The source images are gray-scale, and their sizes are (384−2,916)×(127−2,713). We center-crop the images and resize them into 1×28×28.\n",
       "    License: CC BY 4.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from medmnist import PneumoniaMNIST\n",
    "import numpy as np\n",
    "from medmnist import INFO, Evaluator\n",
    "import matplotlib.image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from skimage.io import imshow, imread,imsave\n",
    "from skimage.util import random_noise\n",
    "import skimage.io\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import dataset_without_pytorch\n",
    "\n",
    "from dataset_without_pytorch import get_loader\n",
    "import keras_tuner\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, UpSampling2D, add\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "PneumoniaMNIST(split='train',download=True, size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flag = 'pneumoniamnist'\n",
    "# data_flag = 'breastmnist'\n",
    "download = True\n",
    "\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 128\n",
    "lr = 0.001\n",
    "\n",
    "info = INFO[data_flag]\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "\n",
    "DataClass = getattr(dataset_without_pytorch, info['python_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/christofferfuglkjaer/.medmnist/pneumoniamnist_128.npz\n",
      "Using downloaded and verified file: /Users/christofferfuglkjaer/.medmnist/pneumoniamnist_128.npz\n",
      "Using downloaded and verified file: /Users/christofferfuglkjaer/.medmnist/pneumoniamnist_128.npz\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "train_dataset = DataClass(split='train', download=download,size = 128)\n",
    "test_dataset = DataClass(split='test', download=download,size = 128)\n",
    "val_dataset= DataClass(split='val', download=download,size = 128)\n",
    "\n",
    "\n",
    "# encapsulate data into dataloader form\n",
    "train_loader = get_loader(dataset=train_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = get_loader(dataset = test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(524, 128, 128)\n",
      "(624, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "train_file = np.load('/Users/christofferfuglkjaer/.medmnist/pneumoniamnist_128.npz')\n",
    "\n",
    "x_train = train_file['train_images']\n",
    "x_test = train_file['test_images']\n",
    "x_val = train_file['val_images']\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_val=x_val.astype('float32') / 255.\n",
    "\n",
    "print (x_val.shape)\n",
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 09:42:22.000117: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2025-02-06 09:42:22.000144: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-02-06 09:42:22.000148: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-02-06 09:42:22.000202: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-02-06 09:42:22.000237: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "noise_factor = 0.2\n",
    "\n",
    "x_train_noisy = x_train + noise_factor * tf.random.normal(shape=x_train.shape)\n",
    "x_test_noisy = x_test + noise_factor * tf.random.normal(shape=x_test.shape)\n",
    "x_val_noisy = x_val + noise_factor * tf.random.normal(shape=x_val.shape)\n",
    "\n",
    "x_train_noisy = tf.clip_by_value(x_train_noisy, clip_value_min=0., clip_value_max=1.)\n",
    "x_test_noisy = tf.clip_by_value(x_test_noisy, clip_value_min=0., clip_value_max=1.)\n",
    "x_val_noisy = tf.clip_by_value(x_val_noisy, clip_value_min=0., clip_value_max=1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i + 1)\n",
    "    plt.title(\"original + noise\")\n",
    "    plt.imshow(tf.squeeze(x_test_noisy[i]))\n",
    "    plt.gray()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, UpSampling2D, add\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "# Encoder\n",
    "\n",
    "n = 128\n",
    "chan = 1\n",
    "input_img = Input(shape=(n, n, chan))\n",
    "\n",
    "l1 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(input_img)\n",
    "l2 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l1)\n",
    "l3 = MaxPooling2D(padding='same')(l2)\n",
    "#l3 = Dropout(0.3)(l3)\n",
    "l4 = Conv2D(64, (3, 3),  padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l3)\n",
    "l5 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l4)\n",
    "l6 = MaxPooling2D(padding='same')(l5)\n",
    "#l3 = Dropout(0.5)(l3)\n",
    "l7 = Conv2D(128, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l6)\n",
    "encoder = Model(input_img, l7)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, UpSampling2D, add\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "# Encoder\n",
    "\n",
    "n = 128\n",
    "chan = 1\n",
    "input_img = Input(shape=(n, n, chan))\n",
    "\n",
    "l1 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(input_img)\n",
    "l2 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l1)\n",
    "l3 = MaxPooling2D(padding='same')(l2)\n",
    "#l3 = Dropout(0.3)(l3)\n",
    "l4 = Conv2D(64, (3, 3),  padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l3)\n",
    "l5 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l4)\n",
    "l6 = MaxPooling2D(padding='same')(l5)\n",
    "#l3 = Dropout(0.5)(l3)\n",
    "l7 = Conv2D(128, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l6)\n",
    "encoder = Model(input_img, l7)\n",
    "encoder.summary()\n",
    "\n",
    "# Decoder\n",
    "\n",
    "l8 = UpSampling2D()(l6)\n",
    "\n",
    "l9 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10),)(l8)\n",
    "l10 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l9)\n",
    "\n",
    "l11 = add([l5, l10])\n",
    "l12 = UpSampling2D()(l11)\n",
    "#l3 = Dropout(0.3)(l3)\n",
    "l13 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l12)\n",
    "l14 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l13)\n",
    "\n",
    "l15 = add([l14, l2])\n",
    "\n",
    "# chan = 3, for RGB\n",
    "decoded = Conv2D(chan, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l15)\n",
    "\n",
    "# Create our network\n",
    "autoencoder = Model(input_img, decoded)\n",
    "# You'll understand later what this is\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tuner.search(x_train, y_train, epochs=5, validation_data=(x_val, y_val))\n",
    "best_model = tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001), loss=losses.MeanSquaredError())\n",
    "autoencoder.fit(x_train_noisy, x_train,epochs=25,batch_size = 16,shuffle=True, validation_data=(x_test_noisy, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_weights = autoencoder.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(x_val[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs=autoencoder.predict(x_val_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(decoded_imgs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_imgs = autoencoder.encoder(x_test_noisy).numpy()\n",
    "# decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(orig, res):\n",
    "    return ((orig - res) ** 2).mean()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "n = 5\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(3, n, i + 1)\n",
    "    plt.imshow(x_test[i])\n",
    "    plt.title(\"original\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # display noisy\n",
    "    ax = plt.subplot(3, n, i + 1 + n)\n",
    "    plt.imshow(x_test_noisy[i])\n",
    "    plt.title(\"noisy\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(3, n, i + 1 + 2 * n)\n",
    "    plt.imshow(decoded_imgs[i])\n",
    "    plt.title(\"reconstructed\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(True)\n",
    "    plt.xlabel(mse(x_test[i], decoded_imgs[i]))\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(decoded_imgs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiple \"networks\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 50/50 netværk \n",
    "2) 4* 25 netværk\n",
    "3) 10 * 10 netværk\n",
    "\n",
    "planen er at træne det her netværk seperat og bruge noget magic til at sætte vægtene sammen til et netværk og så evaluerer dem mod det fulde netværk \n",
    "\n",
    "Vi kører alle netværk ved 25 epoker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_train_noisy_501 = np.split(x_train_noisy,2)\n",
    "x_testnoisy_501 = np.split(x_test_noisy,2)\n",
    "x_train_501 = np.split(x_train,2)\n",
    "x_test_501 = np.split(x_test,2)\n",
    "x_val_noisy501 = np.split(x_val_noisy,2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 50.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 128\n",
    "chan = 1\n",
    "\n",
    "weights = []\n",
    "epochs = 1\n",
    "batchsize = 8\n",
    "\n",
    "for i in range(len(x_train_501)):\n",
    "    print(f\"starter på at træne netværk {i+1}\")\n",
    "\n",
    "    input_img = Input(shape=(n, n, chan))\n",
    "\n",
    "    l1 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(input_img)\n",
    "    l2 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l1)\n",
    "    l3 = MaxPooling2D(padding='same')(l2)\n",
    "    #l3 = Dropout(0.3)(l3)\n",
    "    l4 = Conv2D(64, (3, 3),  padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l3)\n",
    "    l5 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l4)\n",
    "    l6 = MaxPooling2D(padding='same')(l5)\n",
    "    #l3 = Dropout(0.5)(l3)\n",
    "    l7 = Conv2D(128, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l6)\n",
    "    encoder = Model(input_img, l7)\n",
    "\n",
    "\n",
    "    # Decoder\n",
    "\n",
    "    l8 = UpSampling2D()(l6)\n",
    "\n",
    "    l9 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10),)(l8)\n",
    "    l10 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l9)\n",
    "\n",
    "    l11 = add([l5, l10])\n",
    "    l12 = UpSampling2D()(l11)\n",
    "    #l3 = Dropout(0.3)(l3)\n",
    "    l13 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l12)\n",
    "    l14 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l13)\n",
    "\n",
    "    l15 = add([l14, l2])\n",
    "\n",
    "\n",
    "    decoded = Conv2D(chan, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l15)\n",
    "\n",
    "    # Create our network\n",
    "    autoencoder501 = Model(input_img, decoded)\n",
    "\n",
    "    autoencoder501.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001), loss=losses.MeanSquaredError())\n",
    "    autoencoder501.fit(x_train_noisy_501[i], x_train_501[i],epochs=50,batch_size = 8,shuffle=True, validation_data=(x_testnoisy_501[i], x_test_501[i]))\n",
    "    weights.append(autoencoder501.get_weights())\n",
    "    print(f\"netværk {i+1} er færdig med at gøre, går videre til netværk {i+2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs=autoencoder.predict(x_val_noisy501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the arrays have the same shape\n",
    "same_shape = all(w1.shape == w2.shape for w1, w2 in zip(weights_501, weights_502))\n",
    "print(same_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de = autoencoder501.predict(x_val)\n",
    "imshow(de[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.evaluate(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights50501 = [ori - w1 for ori, w1 in zip(ori_weights, weights_501)]\n",
    "weights50502 = [ori - w2 for ori, w2 in zip(ori_weights, weights_502)]\n",
    "weights5050 = [(w1 +w2)/2 + ori for w1, w2,ori in zip(weights50501, weights50502, ori_weights)]\n",
    "autoencoder.set_weights(weights5050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_val)\n",
    "imshow(decoded_imgs[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 25-25\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.32941177, 0.34117648, 0.3529412 , ..., 0.04705882,\n",
       "         0.04705882, 0.04705882],\n",
       "        [0.36078432, 0.36862746, 0.3764706 , ..., 0.03921569,\n",
       "         0.04313726, 0.04705882],\n",
       "        [0.3764706 , 0.38431373, 0.39215687, ..., 0.03921569,\n",
       "         0.04313726, 0.04313726],\n",
       "        ...,\n",
       "        [0.61960787, 0.627451  , 0.654902  , ..., 0.58431375,\n",
       "         0.5019608 , 0.46666667],\n",
       "        [0.6117647 , 0.6392157 , 0.6627451 , ..., 0.5921569 ,\n",
       "         0.5019608 , 0.49019608],\n",
       "        [0.61960787, 0.6392157 , 0.6627451 , ..., 0.5921569 ,\n",
       "         0.49803922, 0.49803922]],\n",
       "\n",
       "       [[0.40784314, 0.39607844, 0.39215687, ..., 0.3764706 ,\n",
       "         0.36862746, 0.42352942],\n",
       "        [0.41568628, 0.40784314, 0.40392157, ..., 0.39607844,\n",
       "         0.3764706 , 0.40392157],\n",
       "        [0.41960785, 0.43529412, 0.43529412, ..., 0.40784314,\n",
       "         0.38431373, 0.38039216],\n",
       "        ...,\n",
       "        [0.7019608 , 0.70980394, 0.72156864, ..., 0.65882355,\n",
       "         0.6431373 , 0.6313726 ],\n",
       "        [0.7254902 , 0.7137255 , 0.7254902 , ..., 0.65882355,\n",
       "         0.64705884, 0.63529414],\n",
       "        [0.75686276, 0.70980394, 0.73333335, ..., 0.6745098 ,\n",
       "         0.65882355, 0.64705884]],\n",
       "\n",
       "       [[0.5647059 , 0.5568628 , 0.5529412 , ..., 0.5137255 ,\n",
       "         0.5176471 , 0.5294118 ],\n",
       "        [0.5686275 , 0.5647059 , 0.56078434, ..., 0.5372549 ,\n",
       "         0.57254905, 0.62352943],\n",
       "        [0.6       , 0.5882353 , 0.5764706 , ..., 0.61960787,\n",
       "         0.6431373 , 0.654902  ],\n",
       "        ...,\n",
       "        [0.6784314 , 0.70980394, 0.7294118 , ..., 0.45882353,\n",
       "         0.6039216 , 0.6431373 ],\n",
       "        [0.69411767, 0.7137255 , 0.7254902 , ..., 0.4862745 ,\n",
       "         0.6039216 , 0.6431373 ],\n",
       "        [0.69803923, 0.7176471 , 0.7058824 , ..., 0.5647059 ,\n",
       "         0.6313726 , 0.6392157 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.31764707, 0.3372549 , 0.36862746, ..., 0.16078432,\n",
       "         0.15294118, 0.15294118],\n",
       "        [0.37254903, 0.36078432, 0.3647059 , ..., 0.16078432,\n",
       "         0.15686275, 0.15294118],\n",
       "        [0.27058825, 0.34117648, 0.37254903, ..., 0.16862746,\n",
       "         0.16470589, 0.16470589],\n",
       "        ...,\n",
       "        [0.47843137, 0.48235294, 0.49411765, ..., 0.49019608,\n",
       "         0.46666667, 0.45490196],\n",
       "        [0.5058824 , 0.5058824 , 0.5176471 , ..., 0.5137255 ,\n",
       "         0.48235294, 0.48235294],\n",
       "        [0.5176471 , 0.52156866, 0.5372549 , ..., 0.5294118 ,\n",
       "         0.5294118 , 0.5058824 ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , ..., 0.3764706 ,\n",
       "         0.38431373, 0.38431373],\n",
       "        [0.01960784, 0.01176471, 0.00392157, ..., 0.38431373,\n",
       "         0.39607844, 0.39607844],\n",
       "        [0.05098039, 0.03921569, 0.03137255, ..., 0.3764706 ,\n",
       "         0.39607844, 0.4       ],\n",
       "        ...,\n",
       "        [0.5529412 , 0.5176471 , 0.4745098 , ..., 0.5686275 ,\n",
       "         0.42745098, 0.42352942],\n",
       "        [0.54901963, 0.5294118 , 0.4509804 , ..., 0.56078434,\n",
       "         0.4509804 , 0.4392157 ],\n",
       "        [0.50980395, 0.5411765 , 0.4509804 , ..., 0.5176471 ,\n",
       "         0.4627451 , 0.45882353]],\n",
       "\n",
       "       [[0.22352941, 0.22352941, 0.23137255, ..., 0.16470589,\n",
       "         0.15686275, 0.14901961],\n",
       "        [0.21960784, 0.22745098, 0.23137255, ..., 0.16470589,\n",
       "         0.16470589, 0.16470589],\n",
       "        [0.21960784, 0.22352941, 0.22745098, ..., 0.27058825,\n",
       "         0.2784314 , 0.2901961 ],\n",
       "        ...,\n",
       "        [0.6901961 , 0.69803923, 0.7019608 , ..., 0.7019608 ,\n",
       "         0.68235296, 0.6627451 ],\n",
       "        [0.68235296, 0.69803923, 0.69803923, ..., 0.7058824 ,\n",
       "         0.6901961 , 0.6666667 ],\n",
       "        [0.68235296, 0.69803923, 0.69803923, ..., 0.70980394,\n",
       "         0.69411767, 0.6745098 ]]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noisy25 = np.split(x_train_noisy,4)\n",
    "x_train25 = np.split(x_train,4)\n",
    "x_test_noisy25 = np.split(x_test_noisy,4)\n",
    "x_test25 = np.split(x_test , 4)\n",
    "x_val25 = np.split(x_val_noisy,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starter med at træne netværk1.\n",
      "netværk1 er færdig med at gøre, går videre til netværk2\n",
      "starter med at træne netværk2.\n",
      "netværk2 er færdig med at gøre, går videre til netværk3\n",
      "starter med at træne netværk3.\n",
      "netværk3 er færdig med at gøre, går videre til netværk4\n",
      "starter med at træne netværk4.\n",
      "netværk4 er færdig med at gøre, går videre til netværk5\n"
     ]
    }
   ],
   "source": [
    "weights = []\n",
    "epochs = 25\n",
    "batchsize = 8\n",
    "agg = 2\n",
    "n = 128\n",
    "chan = 1\n",
    "\n",
    "for j in agg:\n",
    "    for i in range(len(x_train25)):\n",
    "    print(f\"starter med at træne netværk {i+1}.\")\n",
    "\n",
    "    input_img = Input(shape=(n, n, chan))\n",
    "\n",
    "    l1 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(input_img)\n",
    "    l2 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l1)\n",
    "    l3 = MaxPooling2D(padding='same')(l2)\n",
    "    #l3 = Dropout(0.3)(l3)\n",
    "    l4 = Conv2D(64, (3, 3),  padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l3)\n",
    "    l5 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l4)\n",
    "    l6 = MaxPooling2D(padding='same')(l5)\n",
    "    #l3 = Dropout(0.5)(l3)\n",
    "    l7 = Conv2D(128, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l6)\n",
    "    encoder = Model(input_img, l7)\n",
    "\n",
    "\n",
    "    # Decoder\n",
    "\n",
    "    l8 = UpSampling2D()(l6)\n",
    "\n",
    "    l9 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10),)(l8)\n",
    "    l10 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l9)\n",
    "\n",
    "    l11 = add([l5, l10])\n",
    "    l12 = UpSampling2D()(l11)\n",
    "    #l3 = Dropout(0.3)(l3)\n",
    "    l13 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l12)\n",
    "    l14 = Conv2D(32, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l13)\n",
    "\n",
    "    l15 = add([l14, l2])\n",
    "\n",
    "    # chan = 3, for RGB\n",
    "    decoded = Conv2D(chan, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l15)\n",
    "\n",
    "    # Create our network\n",
    "    autoencoder25 = Model(input_img, decoded)\n",
    "    # You'll understand later what this is\n",
    "\n",
    "    autoencoder25.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001), loss=losses.MeanSquaredError())\n",
    "    autoencoder25.fit(x_train_noisy25[i], x_train25[i],epochs=epochs,batch_size = batchsize,shuffle=True, validation_data=(x_test_noisy25[i], x_test25[i]),verbose=0,)\n",
    "    y = autoencoder25.get_weights()\n",
    "    weights.append(y)\n",
    "    print(f\"netværk {i+1} er færdig med at gøre, går videre til netværk {i+2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
